{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening Data and Trialing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my first run through of this data challenge. It wasnt written at the time with the idea that it would be read by anyone else, so it is not nearly as verbosely commented as Final_Submission.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_log_error as rmsler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Holidays = pd.read_csv('Data/holidays_events.csv', \n",
    "                       parse_dates=['date'], \n",
    "                       index_col=['date'])\n",
    "Oil_prices = pd.read_csv('Data/oil.csv', \n",
    "                       parse_dates=['date'], \n",
    "                       index_col=['date'])\n",
    "Stores = pd.read_csv('Data/stores.csv')\n",
    "Test = pd.read_csv('Data/test.csv',\n",
    "                       parse_dates=['date'],  \n",
    "                       index_col=['id'])\n",
    "Train = pd.read_csv('Data/train.csv',\n",
    "                       parse_dates=['date'],  \n",
    "                       index_col=['id'])\n",
    "Transactions = pd.read_csv('Data/transactions.csv',\n",
    "                       parse_dates=['date'], \n",
    "                       index_col=['date'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building familiarity with the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts at 2013-01-01, and ends on 2017-08-15.\n",
      "Testing starts at 2017-08-16, and ends on 2017-08-31.\n"
     ]
    }
   ],
   "source": [
    "dates_training = list(Train['date'])\n",
    "dates_test = list(Test['date'])\n",
    "\n",
    "start_tr, end_tr = dates_training[0].date(), dates_training[-1].date()\n",
    "start_ts, end_ts = dates_test[0].date(), dates_test[-1].date()\n",
    "\n",
    "print(f'Training starts at {start_tr}, and ends on {end_tr}.')\n",
    "print(f'Testing starts at {start_ts}, and ends on {end_ts}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to forecast sales across many different stores and for many different food groups. There are 54 unique stores across many regions, and 33 subgroups of food types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000888</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000889</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000890</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000891</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000892</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr      family  onpromotion\n",
       "id                                                    \n",
       "3000888 2017-08-16          1  AUTOMOTIVE            0\n",
       "3000889 2017-08-16          1   BABY CARE            0\n",
       "3000890 2017-08-16          1      BEAUTY            2\n",
       "3000891 2017-08-16          1   BEVERAGES           20\n",
       "3000892 2017-08-16          1       BOOKS            0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a 2 week forecasting task, a way of sorting out the validation is by separating out the last 2 weeks of data, and using this as the validation set. We select the second so that the validaion set starts the day after the payday, like the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start = \"2016-01-01\"\n",
    "validation_start = \"2017-08-02\"\n",
    "validation_end   = \"2017-08-15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given a hint that in Ecuador they are paid on the 1st and the 15th of every month. We are also told that econmic productivity depends a lot on oil prices. \n",
    "Lets add in a pay day flag, and an oil prices flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data = pd.concat([Train], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day_of_month_tr = All_data['date'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# Create 'payday' column with 1 if day is 1, 15, or last day of the month, else 0\n",
    "All_data.loc[:, 'payday'] = np.where(All_data['date'].dt.day.isin([1, 15]) | (All_data['date'] == last_day_of_month_tr), 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have oil prices, so lets add those in as a feature. Note these have been forward filled to deal with missing values (and a single backfill to fill element at 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data = All_data.merge(Oil_prices, on='date', how='left')\n",
    "All_data.dcoilwtico = All_data.dcoilwtico.ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add in a simple set of date based features. These will be year, month, day of week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def day_feature_engineering(df):\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding national holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you could be more accurate if you were to consider all of the stores which are affected by any given holiday, and including these as flags i.e. 'affected by holiday' column. I do not opt to do this. This allows for omission of the entire store dataset. A possible extension would be to add these back in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_hols = Holidays.loc[(Holidays['locale'] == 'National') & (~Holidays['transferred'])]\n",
    "\n",
    "# Create a column indicating national holidays in Train\n",
    "All_data['is_holiday'] = All_data.index.isin(national_hols.index).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Feature inclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add in some features which are statistical averages over prior performace of a particular product type on a given day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make a new df which has all of the mean sales in for each product, and stitch these together \n",
    "mean_sales = All_data.groupby(['store_nbr', 'family']).sales.mean().reset_index()\n",
    "All_data = pd.merge(All_data, mean_sales, on=['store_nbr', 'family'], suffixes=('', '_mean'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_data.dcoilwtico.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational Feature Inclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of features we add in are lag features. We want a 7 day, 15 day and 28 day lag feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training   = All_data.loc[All_data['date'] < validation_start]\n",
    "Validation = All_data.loc[(All_data['date'] >= validation_start) & (All_data['date'] <= validation_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>payday</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>sales_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2975940</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975941</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975942</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0</td>\n",
       "      <td>2.408551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975943</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>2645.000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1587.748812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975944</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000883</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>438.133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>483.880389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000884</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>154.553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>88.762428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000885</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2419.729</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>969.134497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000886</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>121.000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>6.051069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000887</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>16.884394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24948 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr                      family     sales  \\\n",
       "2975940 2017-08-02          1                  AUTOMOTIVE     4.000   \n",
       "2975941 2017-08-02          1                   BABY CARE     0.000   \n",
       "2975942 2017-08-02          1                      BEAUTY     2.000   \n",
       "2975943 2017-08-02          1                   BEVERAGES  2645.000   \n",
       "2975944 2017-08-02          1                       BOOKS     0.000   \n",
       "...            ...        ...                         ...       ...   \n",
       "3000883 2017-08-15          9                     POULTRY   438.133   \n",
       "3000884 2017-08-15          9              PREPARED FOODS   154.553   \n",
       "3000885 2017-08-15          9                     PRODUCE  2419.729   \n",
       "3000886 2017-08-15          9  SCHOOL AND OFFICE SUPPLIES   121.000   \n",
       "3000887 2017-08-15          9                     SEAFOOD    16.000   \n",
       "\n",
       "         onpromotion  payday  dcoilwtico  is_holiday   sales_mean  \n",
       "2975940            0       0       49.60           0     3.251188  \n",
       "2975941            0       0       49.60           0     0.000000  \n",
       "2975942            1       0       49.60           0     2.408551  \n",
       "2975943           25       0       49.60           0  1587.748812  \n",
       "2975944            0       0       49.60           0     0.125297  \n",
       "...              ...     ...         ...         ...          ...  \n",
       "3000883            0       1       47.57           0   483.880389  \n",
       "3000884            1       1       47.57           0    88.762428  \n",
       "3000885          148       1       47.57           0   969.134497  \n",
       "3000886            8       1       47.57           0     6.051069  \n",
       "3000887            0       1       47.57           0    16.884394  \n",
       "\n",
       "[24948 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now artificially remove all of the sales data from the validation set, so that it has to get values from lag column \n",
    "val_s = Validation.copy()\n",
    "val_s.sales = np.nan\n",
    "train_and_val = pd.concat([Training, val_s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add lag features \n",
    "def add_lag_features(df, lags):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df['sales'].shift(lag)\n",
    "        # Fill missing values in the lagged columns with values from the corresponding lag column\n",
    "        # It is inelegant, but we have to do this twice to fill the full region of consideration \n",
    "        df[f'lag_{lag}'] = df[f'lag_{lag}'].fillna(df[f'lag_{lag}'].shift(lag))\n",
    "        df[f'lag_{lag}'] = df[f'lag_{lag}'].fillna(df[f'lag_{lag}'].shift(lag))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dfs = []\n",
    "lags = [7, 14, 28]\n",
    "sorted_df = train_and_val.sort_values(by = ['store_nbr', 'family'])\n",
    "for (store_nbr, family), group_df in sorted_df.groupby(['store_nbr', 'family']):\n",
    "    # Apply lag features to the group\n",
    "    group_df_with_lags = add_lag_features(group_df, lags)\n",
    "    \n",
    "    # Append the modified group DataFrame to the list\n",
    "    group_dfs.append(group_df_with_lags)\n",
    "\n",
    "# Concatenate all group DataFrames back into one DataFrame\n",
    "processed_df = pd.concat(group_dfs)\n",
    "\n",
    "# Now processed_df contains the original DataFrame with lag features added group by group\n",
    "pd.DataFrame(processed_df).tail(30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>payday</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>sales_mean</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>lag_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.97</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993627</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995409</th>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997191</th>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998973</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.59</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000755</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000888 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr      family  sales  onpromotion  payday  \\\n",
       "0       2013-01-01          1  AUTOMOTIVE    0.0            0       1   \n",
       "1782    2013-01-02          1  AUTOMOTIVE    2.0            0       0   \n",
       "3564    2013-01-03          1  AUTOMOTIVE    3.0            0       0   \n",
       "5346    2013-01-04          1  AUTOMOTIVE    3.0            0       0   \n",
       "7128    2013-01-05          1  AUTOMOTIVE    5.0            0       0   \n",
       "...            ...        ...         ...    ...          ...     ...   \n",
       "2993627 2017-08-11         54     SEAFOOD    NaN            0       0   \n",
       "2995409 2017-08-12         54     SEAFOOD    NaN            1       0   \n",
       "2997191 2017-08-13         54     SEAFOOD    NaN            0       0   \n",
       "2998973 2017-08-14         54     SEAFOOD    NaN            0       0   \n",
       "3000755 2017-08-15         54     SEAFOOD    NaN            0       1   \n",
       "\n",
       "         dcoilwtico  is_holiday  sales_mean  lag_7  lag_14  lag_28  \n",
       "0             93.14           0    3.251188    NaN     NaN     NaN  \n",
       "1782          93.14           0    3.251188    NaN     NaN     NaN  \n",
       "3564          92.97           0    3.251188    NaN     NaN     NaN  \n",
       "5346          93.12           0    3.251188    NaN     NaN     NaN  \n",
       "7128          93.12           0    3.251188    NaN     NaN     NaN  \n",
       "...             ...         ...         ...    ...     ...     ...  \n",
       "2993627       48.81           0    1.744656    4.0     4.0     0.0  \n",
       "2995409       48.81           0    1.744656    4.0     4.0     2.0  \n",
       "2997191       48.81           0    1.744656    4.0     4.0     5.0  \n",
       "2998973       47.59           0    1.744656    4.0     4.0     3.0  \n",
       "3000755       47.57           0    1.744656    3.0     3.0     6.0  \n",
       "\n",
       "[3000888 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_family_to_integer(df):\n",
    "    # Assuming df is your DataFrame containing the data\n",
    "    \n",
    "    # Create a sorted list of unique families\n",
    "    unique_families = sorted(df['family'].unique())\n",
    "    \n",
    "    # Create a dictionary to map each family to a unique integer\n",
    "    family_to_integer = {family: idx for idx, family in enumerate(unique_families)}\n",
    "    \n",
    "    # Apply the encoding to the 'family' column\n",
    "    df['family'] = df['family'].map(family_to_integer)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame containing the data with 'family' column\n",
    "df_encoded = target_encode_family_to_integer(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>payday</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>sales_mean</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.97</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.251188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993627</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995409</th>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997191</th>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998973</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.59</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000755</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1.744656</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000888 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr  family  sales  onpromotion  payday  dcoilwtico  \\\n",
       "0       2013-01-01          1       0    0.0            0       1       93.14   \n",
       "1782    2013-01-02          1       0    2.0            0       0       93.14   \n",
       "3564    2013-01-03          1       0    3.0            0       0       92.97   \n",
       "5346    2013-01-04          1       0    3.0            0       0       93.12   \n",
       "7128    2013-01-05          1       0    5.0            0       0       93.12   \n",
       "...            ...        ...     ...    ...          ...     ...         ...   \n",
       "2993627 2017-08-11         54      32    NaN            0       0       48.81   \n",
       "2995409 2017-08-12         54      32    NaN            1       0       48.81   \n",
       "2997191 2017-08-13         54      32    NaN            0       0       48.81   \n",
       "2998973 2017-08-14         54      32    NaN            0       0       47.59   \n",
       "3000755 2017-08-15         54      32    NaN            0       1       47.57   \n",
       "\n",
       "         is_holiday  sales_mean  lag_7  lag_14  lag_28  day  month  year  \\\n",
       "0                 0    3.251188    NaN     NaN     NaN    1      1  2013   \n",
       "1782              0    3.251188    NaN     NaN     NaN    2      1  2013   \n",
       "3564              0    3.251188    NaN     NaN     NaN    3      1  2013   \n",
       "5346              0    3.251188    NaN     NaN     NaN    4      1  2013   \n",
       "7128              0    3.251188    NaN     NaN     NaN    5      1  2013   \n",
       "...             ...         ...    ...     ...     ...  ...    ...   ...   \n",
       "2993627           0    1.744656    4.0     4.0     0.0   11      8  2017   \n",
       "2995409           0    1.744656    4.0     4.0     2.0   12      8  2017   \n",
       "2997191           0    1.744656    4.0     4.0     5.0   13      8  2017   \n",
       "2998973           0    1.744656    4.0     4.0     3.0   14      8  2017   \n",
       "3000755           0    1.744656    3.0     3.0     6.0   15      8  2017   \n",
       "\n",
       "         dayofweek  \n",
       "0                1  \n",
       "1782             2  \n",
       "3564             3  \n",
       "5346             4  \n",
       "7128             5  \n",
       "...            ...  \n",
       "2993627          4  \n",
       "2995409          5  \n",
       "2997191          6  \n",
       "2998973          0  \n",
       "3000755          1  \n",
       "\n",
       "[3000888 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = day_feature_engineering(df_encoded)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we re add in the sales column now that the lags have been calculated blindly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['sales'] = All_data['sales']\n",
    "# train_data = df_encoded.loc[(df_encoded['date'] < validation_start) & ~(())]\n",
    "# valid_data  = df_encoded.loc[(df_encoded['date'] >= validation_start) & (df_encoded['date'] <= validation_end)]\n",
    "# test_data = df_encoded.loc[df_encoded['date'] > validation_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_w_quake = df_encoded.loc[(df_encoded['date'] > training_start) & (df_encoded['date'] < validation_start)]\n",
    "train_data = train_data_w_quake.loc[~((train_data_w_quake['date'] >= \"2016-04-16\") & (train_data_w_quake['date'] <= \"2016-05-16\"))]\n",
    "val_data = df_encoded.loc[df_encoded['date'] >= validation_start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now make use of light gmb to forecast the trends in this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded['sales'] = All_data['sales']\n",
    "# train_data = df_encoded.loc[df_encoded['date'] < validation_start]\n",
    "# valid_data  = df_encoded.loc[(df_encoded['date'] >= validation_start) & (df_encoded['date'] <= validation_end)]\n",
    "# test_data = df_encoded.loc[df_encoded['date'] > validation_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['store_nbr', 'family', 'onpromotion', 'payday', 'dcoilwtico', 'day', 'month', 'year', 'dayofweek', 'is_holiday', \n",
    "            'sales_mean', 'lag_7', 'lag_14', 'lag_28']\n",
    "target = 'sales'\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_valid = val_data[features]\n",
    "y_valid = val_data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [20, 31, 50, 100],\n",
    "    'feature_fraction': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'lambda_l1': [0.0, 0.1, 0.5, 1.0],\n",
    "    'lambda_l2': [0.0, 0.1, 0.5, 1.0],\n",
    "    'min_child_samples': [10, 20, 30, 50],\n",
    "    'bagging_fraction': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'bagging_freq': [1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 76800 candidates, totalling 384000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39mrmse_scorer, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Best parameters\u001b[39;00m\n\u001b[0;32m      8\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    911\u001b[0m         )\n\u001b[0;32m    912\u001b[0m     )\n\u001b[1;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\harry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMRegressor(objective='tweedie', metric='rmse', boosting_type='gbdt', verbose=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=rmse_scorer, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non grid search method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "valid_dataset = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "params = {\n",
    "    'objective': 'tweedie',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.9,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'min_child_samples': 20,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.848225\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.218012\n",
      "[LightGBM] [Debug] init for col-wise cost 0.050904 seconds, init for row-wise cost 0.119739 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1626\n",
      "[LightGBM] [Info] Number of data points in the train set: 2975940, number of used features: 13\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Info] Start training from score 5.877538\n",
      "[LightGBM] [Debug] Re-bagging, using 2381659 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380509 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2380944 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381049 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380264 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 2381943 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2380863 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380968 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2379868 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2381197 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380901 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381363 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2381021 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380625 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381431 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381559 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381525 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381997 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380418 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2381463 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380953 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380713 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380714 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 2380602 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381395 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381358 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381056 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2382542 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2382001 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381103 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380979 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381108 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380980 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380370 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2379823 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2381403 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380075 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380203 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380929 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380312 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 2379852 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380656 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380949 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2379699 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380454 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381117 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2379891 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2380994 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381081 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380318 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381049 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380358 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380570 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380551 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380154 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380540 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 2381118 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380927 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2381086 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380799 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381034 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380319 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381063 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380986 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381199 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380414 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2379600 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380250 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380870 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381171 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380084 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380742 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381328 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 2380721 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381032 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 2380382 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380755 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381308 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381138 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380837 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381157 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2380368 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380812 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380832 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381041 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2379613 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381192 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381103 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381380 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381268 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 2381379 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2381356 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380861 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2379604 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380822 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380233 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380247 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2379887 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380403 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 2380730 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381103 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381128 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380890 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2380988 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380951 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 2380978 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381166 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380695 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2379513 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381099 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380406 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381213 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380621 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381421 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2380066 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380264 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2379482 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380847 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380786 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380047 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381611 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381201 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380649 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380628 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380984 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380128 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2381189 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380793 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2380196 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2378808 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381578 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380019 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381049 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380250 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381140 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380676 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2381121 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380777 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381315 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380606 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2381120 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381489 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380853 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 2380659 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380979 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381404 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2380635 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381386 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381267 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2381532 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381239 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380479 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380530 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 2381462 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2382017 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2382291 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2380734 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381703 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380486 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380478 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381524 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380858 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381629 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 2381092 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 2380885 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380404 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381384 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381458 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380139 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380060 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2379586 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380888 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380915 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2380782 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 2381026 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 2381197 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2380705 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2381195 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2379357 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380615 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381142 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381026 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2380368 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381246 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2379168 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2382309 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380564 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380465 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2380577 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2380883 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 2379195 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 2381192 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 2381410 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 2380224 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params,\n",
    "                  train_dataset,\n",
    "                  num_boost_round=1000,\n",
    "                  valid_sets=[train_dataset, valid_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "y_train_pred = model.predict(X_train, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSLE: 0.18950438671392358\n",
      "Train RMSLE: 0.2046317990224517\n"
     ]
    }
   ],
   "source": [
    "y_train_clipped = np.clip(y_train_pred, 0, None)\n",
    "rmsle1 = rmsler(y_train, y_train_clipped)\n",
    "y_pred_clipped = np.clip(y_valid_pred, 0, None)\n",
    "\n",
    "rmsle2 = rmsler(y_valid, y_pred_clipped)\n",
    "print(f'Validation RMSLE: {rmsle2}')\n",
    "print(f'Train RMSLE: {rmsle1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = model.feature_importance(importance_type='gain')  # or 'gain'\n",
    "feature_names = model.feature_name()\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "})\n",
    "\n",
    "# Sort the dataframe by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'objective': 'regression', \n",
    "#     'metric': 'rmse',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'learning_rate': 0.05,\n",
    "#     'num_leaves': 31,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'bagging_freq': 5,\n",
    "#     'verbose': 2\n",
    "# }\n",
    "\n",
    "# model = lgb.train(params,\n",
    "#                   train_dataset,\n",
    "#                   num_boost_round=1000,\n",
    "#                   valid_sets=[train_dataset, valid_dataset])\n",
    "\n",
    "# resulted in Validation RMSLE: 12.657290009315009\n",
    "# this high rmsle was dut to an incorrect index alignment between the two datasets being input into the rmsle checker \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'objective': 'tweedie', # regression used before\n",
    "#     'metric': 'rmse',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'learning_rate': 0.05,\n",
    "#     'num_leaves': 31,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'lambda_l1': 0.1,\n",
    "#     'lambda_l2': 0.1,\n",
    "#     'min_child_samples': 20,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'bagging_freq': 5,\n",
    "#     'verbose': 2\n",
    "# } \n",
    "# model = lgb.train(params,\n",
    "#                   train_dataset,\n",
    "#                   num_boost_round=1000,\n",
    "#                   valid_sets=[train_dataset, valid_dataset])\n",
    "# resulted in Validation RMSLE: 0.1895043835463883"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dfs = []\n",
    "lags = [7, 14, 28]\n",
    "sorted_df_all = All_data.sort_values(by = ['store_nbr', 'family'])\n",
    "for (store_nbr, family), group_df in sorted_df_all.groupby(['store_nbr', 'family']):\n",
    "    # Apply lag features to the group\n",
    "    group_df_with_lags = add_lag_features(group_df, lags)\n",
    "    \n",
    "    # Append the modified group DataFrame to the list\n",
    "    group_dfs.append(group_df_with_lags)\n",
    "\n",
    "# Concatenate all group DataFrames back into one DataFrame\n",
    "processed_df_all = pd.concat(group_dfs)\n",
    "pd.DataFrame(processed_df_all);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harry\\AppData\\Local\\Temp\\ipykernel_21840\\4227364947.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['family'] = df['family'].map(family_to_integer)\n"
     ]
    }
   ],
   "source": [
    "test_data = processed_df_all.loc[processed_df_all['date'] > validation_end]\n",
    "test_data = target_encode_family_to_integer(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "y_test_pred = pd.DataFrame(model.predict(X_test, num_iteration=model.best_iteration), columns=['sales'], index=y_test.index)\n",
    "\n",
    "#y_test_df = pd.DataFrame(y_test_pred.values, columns=['sales'], index=y_test.index)\n",
    "y_test_pred = y_test_pred.rename_axis('id')\n",
    "y_test_pred.to_csv('Submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
